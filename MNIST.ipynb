{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composed-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "\n",
    "# Load dataset\n",
    "train = datasets.MNIST(curr_dir, train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(curr_dir, train=False, download=True,\n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pharmaceutical-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load batch\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authorized-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "configured-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build network\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # fully connected layer (input, output)\n",
    "        self.fc1 = nn.Linear(784, 64) # input layer\n",
    "        self.fc2 = nn.Linear(64, 64) # hidden\n",
    "        self.fc3 = nn.Linear(64, 64) # hidden\n",
    "        self.fc4 = nn.Linear(64, 10) # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # how data is feed forward through layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1) # Softmax convert numbers to probabilities\n",
    "        \n",
    "        return x\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleased-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8870e-01, 4.5895e-01, 5.2126e-01, 8.2276e-01, 5.7905e-01, 4.4385e-02,\n",
       "         8.8519e-01, 1.7526e-01, 6.0793e-01, 7.7147e-01, 3.9809e-03, 5.3486e-01,\n",
       "         1.9130e-01, 6.6637e-02, 3.8041e-01, 3.9901e-01, 2.5414e-01, 2.8421e-01,\n",
       "         4.1730e-02, 5.2091e-03, 1.7356e-01, 9.3105e-01, 8.5480e-01, 6.0481e-01,\n",
       "         3.5054e-01, 4.4501e-01, 7.8347e-01, 5.9879e-01],\n",
       "        [5.7473e-01, 6.5527e-01, 4.0551e-01, 1.6584e-01, 4.1889e-01, 8.6490e-01,\n",
       "         5.8185e-01, 3.1285e-01, 3.5441e-01, 9.4413e-01, 6.9615e-01, 7.5845e-01,\n",
       "         3.4451e-01, 5.0843e-01, 2.1550e-01, 1.0327e-01, 6.4969e-01, 5.7878e-01,\n",
       "         9.7584e-01, 9.1170e-01, 6.9635e-01, 8.9898e-01, 9.4706e-01, 5.5853e-02,\n",
       "         9.7634e-02, 9.8516e-02, 3.4151e-01, 8.1281e-01],\n",
       "        [3.7583e-01, 9.8827e-01, 3.5945e-01, 5.7603e-01, 8.6626e-01, 7.8527e-01,\n",
       "         7.9029e-01, 7.8760e-01, 7.3239e-01, 7.6074e-01, 8.3627e-01, 6.8464e-01,\n",
       "         9.4495e-01, 8.8526e-01, 5.2470e-01, 6.3966e-01, 3.2551e-01, 9.4293e-01,\n",
       "         9.1052e-01, 1.5438e-01, 4.0239e-01, 2.6198e-01, 1.9672e-01, 9.7432e-01,\n",
       "         1.3499e-01, 5.1584e-01, 6.6565e-01, 7.5720e-01],\n",
       "        [4.0366e-01, 6.5584e-01, 8.3461e-01, 3.9971e-01, 7.3331e-01, 8.9928e-01,\n",
       "         2.9547e-01, 4.5512e-01, 3.5803e-02, 4.6353e-01, 8.0976e-01, 9.5579e-01,\n",
       "         4.4465e-04, 8.9293e-01, 7.3463e-01, 8.9753e-01, 2.7705e-01, 9.6101e-02,\n",
       "         9.1446e-01, 1.4580e-01, 1.6068e-01, 8.4448e-01, 2.3843e-01, 1.9649e-01,\n",
       "         4.8221e-01, 9.2570e-01, 5.0549e-03, 7.5337e-01],\n",
       "        [6.8861e-01, 7.1913e-02, 8.4887e-01, 7.8806e-01, 8.9587e-01, 7.2535e-01,\n",
       "         7.6956e-01, 3.1097e-01, 1.2175e-01, 7.1843e-01, 2.8864e-01, 6.1495e-02,\n",
       "         1.8082e-01, 2.1882e-01, 4.5083e-01, 2.4488e-01, 6.4706e-01, 8.4451e-01,\n",
       "         7.8562e-01, 7.7585e-01, 2.7181e-01, 4.0867e-02, 8.1164e-01, 6.3782e-01,\n",
       "         5.1127e-02, 2.8965e-01, 9.8244e-01, 1.7240e-01],\n",
       "        [8.9310e-01, 2.1229e-01, 1.1616e-01, 3.4301e-01, 8.3177e-01, 7.9196e-01,\n",
       "         4.4691e-01, 6.3119e-01, 5.8636e-01, 8.2387e-01, 5.3523e-01, 4.2919e-02,\n",
       "         2.2680e-01, 7.6393e-01, 2.4961e-03, 8.5192e-01, 6.1818e-01, 2.5602e-01,\n",
       "         7.5069e-01, 6.5565e-02, 9.8300e-01, 4.9709e-01, 9.8710e-01, 5.2305e-01,\n",
       "         3.8587e-01, 5.8074e-01, 4.4020e-01, 1.9131e-01],\n",
       "        [8.3727e-01, 8.1844e-01, 5.5333e-01, 4.5667e-01, 3.5237e-01, 9.7308e-01,\n",
       "         6.5111e-01, 6.5533e-01, 5.4176e-01, 6.6426e-02, 7.2431e-02, 5.9070e-01,\n",
       "         1.5094e-02, 4.0843e-01, 8.4394e-01, 1.3541e-01, 9.0351e-01, 4.9693e-01,\n",
       "         7.1072e-01, 5.4633e-01, 9.6444e-02, 3.3672e-01, 5.0732e-01, 8.9431e-01,\n",
       "         4.9037e-01, 6.5638e-01, 8.6562e-01, 3.6276e-01],\n",
       "        [9.7897e-01, 6.1124e-01, 7.7562e-01, 2.5274e-01, 2.0392e-01, 2.3445e-01,\n",
       "         6.8405e-01, 7.8204e-01, 8.8938e-01, 5.7153e-01, 1.9924e-01, 9.4967e-02,\n",
       "         2.7994e-01, 2.7969e-01, 8.6227e-01, 9.4460e-01, 1.6012e-01, 7.3369e-01,\n",
       "         8.7255e-01, 6.4596e-01, 7.6769e-01, 9.1141e-01, 5.6714e-01, 3.8451e-02,\n",
       "         7.2127e-01, 9.5881e-01, 8.7146e-01, 8.4320e-01],\n",
       "        [1.0348e-01, 1.9247e-01, 9.3810e-01, 8.5571e-01, 1.9024e-01, 1.2062e-01,\n",
       "         3.7269e-01, 1.9436e-01, 1.4484e-01, 5.7659e-01, 8.2871e-01, 5.7202e-01,\n",
       "         9.1276e-01, 8.7072e-01, 1.4392e-01, 4.2020e-01, 8.7366e-01, 5.8720e-01,\n",
       "         1.1325e-01, 1.5054e-01, 9.9579e-01, 1.0127e-01, 6.6288e-01, 1.8736e-01,\n",
       "         7.1671e-01, 1.6843e-01, 9.1566e-01, 3.0297e-01],\n",
       "        [5.9802e-01, 2.8162e-01, 8.4994e-01, 6.8166e-01, 3.6386e-01, 6.9123e-01,\n",
       "         5.8808e-01, 6.7842e-01, 1.3339e-01, 4.2730e-01, 4.2278e-01, 8.5754e-01,\n",
       "         7.5495e-02, 9.8097e-01, 7.7804e-01, 3.7816e-01, 2.4658e-01, 4.9162e-01,\n",
       "         1.6947e-01, 7.8477e-01, 5.1956e-01, 9.2964e-02, 2.3293e-01, 4.4090e-01,\n",
       "         3.5320e-01, 4.1710e-02, 1.6669e-01, 4.8378e-01],\n",
       "        [4.2771e-01, 9.6513e-01, 6.5286e-01, 8.4726e-01, 2.2195e-01, 8.4501e-01,\n",
       "         9.2100e-01, 7.9868e-01, 9.6623e-01, 7.7345e-01, 2.6896e-01, 8.6436e-01,\n",
       "         2.7920e-01, 8.1311e-01, 6.9538e-01, 6.7596e-01, 6.3557e-01, 7.8453e-01,\n",
       "         6.8773e-01, 2.5325e-01, 1.5097e-01, 1.8249e-01, 5.6231e-01, 8.8381e-01,\n",
       "         6.4691e-01, 3.3903e-01, 9.2559e-01, 6.4967e-01],\n",
       "        [8.5392e-02, 7.4857e-01, 8.8270e-01, 4.8904e-01, 8.0255e-02, 8.9697e-01,\n",
       "         1.4724e-01, 3.1537e-01, 7.3708e-01, 7.0258e-01, 5.3652e-01, 7.2736e-01,\n",
       "         9.0984e-01, 4.3912e-01, 2.7888e-01, 2.2217e-01, 2.9569e-01, 9.4659e-01,\n",
       "         1.5907e-01, 3.3777e-01, 5.0556e-01, 7.8107e-01, 6.2442e-01, 5.6452e-01,\n",
       "         4.4995e-01, 5.4723e-01, 1.8196e-01, 3.4588e-01],\n",
       "        [3.6014e-01, 3.3862e-01, 7.5593e-01, 5.2154e-01, 5.8599e-01, 3.7640e-01,\n",
       "         8.7490e-01, 6.4698e-01, 9.2136e-01, 5.8902e-01, 3.0462e-01, 3.4714e-01,\n",
       "         1.7025e-01, 3.5313e-01, 8.9044e-01, 5.0177e-01, 7.8357e-01, 8.9799e-01,\n",
       "         5.7910e-01, 1.4669e-01, 4.5766e-02, 9.5626e-01, 5.5861e-01, 5.0289e-01,\n",
       "         8.2548e-01, 8.7644e-01, 3.7250e-01, 2.3188e-02],\n",
       "        [4.5674e-02, 9.3416e-01, 9.4385e-01, 6.5715e-01, 1.3060e-02, 3.9254e-01,\n",
       "         8.3264e-01, 8.8399e-01, 7.3546e-01, 4.0651e-01, 1.9025e-02, 8.7183e-01,\n",
       "         6.8284e-01, 8.0480e-01, 5.5762e-01, 3.0456e-01, 6.1428e-01, 8.2104e-01,\n",
       "         2.8161e-02, 9.1557e-02, 6.1442e-01, 4.2513e-01, 3.2422e-01, 4.5870e-01,\n",
       "         9.6751e-01, 1.1952e-01, 3.2451e-01, 7.7238e-01],\n",
       "        [6.1002e-01, 3.6392e-01, 2.9034e-02, 5.0487e-01, 4.0815e-01, 3.6185e-01,\n",
       "         2.1363e-01, 5.4332e-01, 4.4478e-01, 7.4152e-01, 9.8338e-01, 4.1917e-02,\n",
       "         8.8690e-01, 9.5542e-01, 2.4717e-01, 8.2131e-01, 6.1461e-01, 2.4944e-01,\n",
       "         7.7209e-01, 8.3213e-01, 1.4243e-02, 8.5562e-01, 2.2176e-01, 4.8815e-01,\n",
       "         9.0620e-01, 8.8576e-01, 4.4302e-01, 6.8307e-01],\n",
       "        [6.2300e-01, 3.0697e-01, 5.6134e-01, 7.5643e-01, 3.5004e-01, 5.5961e-01,\n",
       "         6.3632e-01, 3.5774e-01, 9.0210e-01, 6.0058e-01, 8.1759e-01, 3.3647e-01,\n",
       "         5.3008e-01, 8.7369e-01, 8.3705e-01, 8.6252e-01, 6.4921e-01, 5.7275e-01,\n",
       "         7.4453e-01, 6.8952e-01, 8.1178e-01, 9.1842e-02, 3.2295e-01, 4.6421e-01,\n",
       "         7.9616e-02, 6.9956e-01, 9.4394e-01, 4.2461e-01],\n",
       "        [8.6832e-01, 4.4712e-01, 7.5770e-01, 3.6207e-01, 2.4084e-01, 9.2301e-01,\n",
       "         2.9279e-01, 1.6596e-01, 3.0073e-01, 7.1448e-01, 1.1601e-01, 7.6512e-01,\n",
       "         2.1520e-01, 5.8591e-01, 8.1139e-01, 2.0989e-01, 5.5387e-01, 2.7355e-01,\n",
       "         5.6838e-01, 9.2464e-01, 2.5608e-01, 6.8444e-01, 8.8835e-01, 8.7614e-01,\n",
       "         7.9143e-01, 1.5544e-01, 3.2263e-01, 4.1215e-01],\n",
       "        [9.1405e-01, 6.6980e-01, 7.1042e-01, 2.4046e-01, 6.9989e-01, 5.3323e-01,\n",
       "         9.5402e-01, 7.7453e-01, 8.2309e-01, 3.8357e-01, 7.2708e-01, 7.5461e-01,\n",
       "         1.4978e-01, 2.9941e-02, 6.4650e-01, 6.4471e-01, 3.7456e-01, 4.6435e-01,\n",
       "         4.7944e-01, 7.1479e-01, 2.9082e-02, 2.3341e-01, 8.1481e-01, 8.5414e-01,\n",
       "         5.6751e-01, 2.5431e-01, 1.0929e-01, 8.3167e-01],\n",
       "        [6.0950e-01, 2.8878e-02, 6.1885e-01, 6.0482e-01, 8.2570e-02, 1.8686e-01,\n",
       "         3.7959e-01, 4.7665e-01, 8.1002e-01, 5.3203e-01, 2.9024e-01, 8.5104e-01,\n",
       "         8.2178e-01, 6.9139e-01, 4.0633e-01, 6.9609e-02, 2.5862e-01, 1.5365e-01,\n",
       "         7.9551e-01, 2.1371e-01, 7.4118e-01, 6.1765e-01, 7.1319e-01, 1.1031e-01,\n",
       "         8.9126e-01, 8.5083e-01, 4.0588e-01, 2.8642e-01],\n",
       "        [4.3657e-01, 5.3402e-01, 4.2779e-01, 3.0101e-02, 8.8919e-01, 4.6505e-01,\n",
       "         6.8994e-01, 6.0352e-01, 4.3778e-01, 7.3236e-01, 8.7939e-01, 6.9668e-01,\n",
       "         5.5729e-01, 5.5770e-01, 1.4247e-01, 8.9158e-01, 8.2627e-01, 4.5653e-01,\n",
       "         1.4955e-01, 7.2199e-01, 8.0957e-01, 3.7266e-01, 9.1829e-01, 8.3466e-01,\n",
       "         8.7295e-01, 2.1933e-01, 6.9476e-01, 1.9548e-01],\n",
       "        [5.3128e-01, 5.2079e-01, 4.3156e-01, 3.8893e-01, 1.1588e-01, 9.1404e-01,\n",
       "         7.9148e-01, 4.3021e-01, 8.6652e-01, 3.8685e-01, 3.3540e-01, 6.7536e-01,\n",
       "         5.8666e-01, 7.6792e-01, 6.5278e-03, 2.0004e-01, 4.5700e-01, 1.4441e-01,\n",
       "         2.6816e-01, 7.7539e-01, 5.3955e-01, 1.3536e-01, 8.9144e-01, 2.1174e-01,\n",
       "         9.2575e-01, 7.0591e-01, 2.3025e-01, 5.4031e-01],\n",
       "        [2.1453e-01, 2.9448e-01, 7.6429e-01, 8.1162e-01, 6.9126e-01, 8.9042e-03,\n",
       "         9.0859e-01, 1.1771e-01, 1.3449e-01, 7.3579e-01, 3.2048e-01, 3.4670e-01,\n",
       "         6.7749e-01, 8.2093e-01, 2.3465e-02, 2.9250e-01, 7.2993e-01, 6.9774e-01,\n",
       "         2.8933e-01, 5.6544e-01, 5.2535e-01, 7.2028e-01, 4.8416e-01, 1.4305e-01,\n",
       "         5.1385e-01, 7.9557e-01, 7.4892e-01, 8.3401e-01],\n",
       "        [9.1120e-01, 8.9688e-01, 2.2158e-01, 3.9439e-01, 7.2040e-01, 2.8044e-01,\n",
       "         7.3130e-01, 9.2264e-01, 1.1016e-01, 4.0188e-01, 3.0187e-01, 1.4816e-01,\n",
       "         9.1994e-01, 9.8505e-01, 9.9602e-01, 7.6619e-01, 8.1233e-01, 1.6806e-01,\n",
       "         4.9437e-01, 7.7160e-02, 1.1191e-01, 2.8386e-01, 4.9709e-01, 8.1944e-02,\n",
       "         2.6504e-01, 1.5208e-01, 6.9435e-01, 7.2859e-01],\n",
       "        [2.3170e-01, 4.2405e-01, 1.9860e-01, 1.9601e-01, 6.3570e-01, 1.2413e-01,\n",
       "         8.5884e-01, 2.0458e-01, 4.2655e-01, 1.5331e-01, 7.3293e-01, 1.3788e-01,\n",
       "         3.3111e-01, 7.5257e-01, 4.3848e-01, 7.9049e-01, 7.5445e-01, 2.8468e-01,\n",
       "         9.0029e-01, 6.3486e-01, 9.2010e-02, 2.4630e-01, 4.0370e-01, 6.2964e-02,\n",
       "         8.4026e-01, 8.6448e-01, 3.2778e-01, 8.0634e-01],\n",
       "        [1.2099e-01, 3.8237e-01, 8.2990e-01, 8.8726e-01, 8.3648e-02, 1.3463e-01,\n",
       "         7.6279e-02, 8.0692e-01, 6.2546e-01, 8.8950e-01, 6.8046e-01, 3.0509e-01,\n",
       "         5.4939e-01, 7.6168e-01, 5.1107e-01, 7.1915e-01, 1.0136e-01, 9.7236e-01,\n",
       "         8.3629e-01, 3.4535e-01, 2.6793e-01, 1.3529e-01, 4.4964e-01, 4.2127e-01,\n",
       "         3.5527e-01, 1.6080e-01, 2.7847e-01, 3.3135e-02],\n",
       "        [4.7797e-01, 1.5332e-01, 3.7793e-01, 2.2507e-01, 8.2522e-01, 8.5700e-01,\n",
       "         1.3821e-01, 8.2711e-01, 8.4210e-01, 4.0431e-01, 9.6914e-01, 1.7965e-01,\n",
       "         9.4124e-01, 1.5770e-01, 1.0876e-01, 7.6105e-01, 3.7537e-03, 1.0783e-01,\n",
       "         8.6349e-01, 3.7069e-01, 4.2731e-01, 9.0028e-01, 1.9126e-01, 5.0457e-01,\n",
       "         8.1355e-01, 9.4046e-01, 9.7320e-01, 3.5373e-01],\n",
       "        [7.9436e-01, 9.3231e-01, 1.0231e-02, 4.2859e-01, 2.4874e-01, 2.5194e-01,\n",
       "         3.2865e-01, 6.0892e-01, 5.3392e-01, 6.9148e-01, 6.0695e-01, 6.9377e-01,\n",
       "         2.1210e-01, 8.5730e-02, 1.8545e-01, 7.6677e-01, 6.0350e-01, 3.7880e-01,\n",
       "         7.2828e-01, 5.5853e-01, 5.3555e-01, 5.8065e-01, 5.3017e-02, 6.5263e-01,\n",
       "         4.8584e-01, 8.9485e-02, 9.6423e-01, 2.4519e-01],\n",
       "        [5.6256e-01, 2.1086e-01, 2.3874e-01, 3.6496e-02, 8.5725e-01, 8.9063e-01,\n",
       "         9.0440e-01, 7.5873e-01, 8.2999e-01, 9.2616e-01, 8.1714e-01, 7.3066e-01,\n",
       "         5.2173e-01, 6.7796e-01, 2.7997e-01, 1.5351e-01, 8.9006e-01, 5.7771e-01,\n",
       "         6.2865e-01, 2.6915e-02, 2.0516e-01, 8.3920e-01, 4.1363e-01, 3.7494e-01,\n",
       "         3.6206e-01, 8.7223e-01, 7.7792e-01, 1.8928e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28, 28))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "biblical-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X.view(-1, 28 * 28)) # -1 for any size of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wrong-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3681, -2.3452, -2.2136, -2.3395, -2.2496, -2.2799, -2.2298, -2.5236,\n",
       "         -2.1970, -2.3202]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "norman-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Set up optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # (what is adjustable, learning rate)\n",
    "\n",
    "EPOCHS = 3 # number of passes\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset: # data is batch\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28 * 28))\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # adjust weight and bias\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broad-renaissance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.988\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Count how many prediction is correct in training set\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28 * 28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "russian-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Count how many prediction is correct in test set\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28 * 28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "entitled-mason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x239da6fbfa0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM00lEQVR4nO3dX6xdZZ3G8eeRKTVWSVoZmBYbxJYLySRznJy0nXTaMCEKclO4cLQXUhNiISmJEpMZwlzIzSTEjBIvGofj0FiMIiba0AsSbBqTg5Ox4UA6UKhKxaK1TavpRXHMlAK/uTiLyaHsvdZh/d2nv+8nOdl7r3edvX5npU/X2utd734dEQJw6Xvf0AUA6AdhB5Ig7EAShB1IgrADSfxFnxu73Mvj/VrR5yaBVP5X/6PX47xHtTUKu+1bJH1T0mWS/iMiHixb//1aoY2+qckmAZQ4FAfHttU+jbd9maTdkj4t6QZJ223fUPf9AHSryWf2DZKORcQrEfG6pB9I2tZOWQDa1iTs10j63YLXJ4pl72B7p+0523MXdL7B5gA00STsoy4CvOve24iYiYjpiJhepuUNNgegiSZhPyFp7YLXH5F0slk5ALrSJOzPSLre9nW2L5f0OUn72ykLQNtqd71FxBu275H0lOa73vZExIutVQagVY362SPiSUlPtlQLgA5xuyyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNJrFFf049tCm0vbNm14a2/botbNtl9OaLbvuKm3/wL5DPVWSQ6Ow2z4u6TVJb0p6IyKm2ygKQPvaOLL/Q0T8sYX3AdAhPrMDSTQNe0j6ie1nbe8ctYLtnbbnbM9d0PmGmwNQV9PT+M0RcdL2VZIO2P5FRLzjilBEzEiakaQrvCoabg9ATY2O7BFxsng8I2mfpA1tFAWgfbXDbnuF7Q+9/VzSpyQdaaswAO1yRL0za9sf0/zRXJr/OPD9iPjXst+5wqtio2+qtb1L2dX/dUVp+yT3lQ/p5jVTpe1/vn3j2LaTW136u+vv/XmdkgZ3KA7qXJwd+cfV/sweEa9I+pvaVQHoFV1vQBKEHUiCsANJEHYgCcIOJMEQ1wlA11o9T508XLFGVft4d2zaWtp++u/O1X7voXBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkag9xrYMhrqOVDcWUpKd3P9zZtu94tVl/ctbhuesev7u0faghsmVDXDmyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS9LMvAdXjtrtT1Z/868/+e0+V9Kvp/QdDoZ8dAGEHsiDsQBKEHUiCsANJEHYgCcIOJEE/+xKQdcx4l5ZqP3qVRv3stvfYPmP7yIJlq2wfsP1y8biyzYIBtG8xp/HfkXTLRcvuk3QwIq6XdLB4DWCCVYY9ImYlnb1o8TZJe4vneyXd1m5ZANpW9wLd1RFxSpKKx6vGrWh7p+0523MXdL7m5gA01fnV+IiYiYjpiJhepuVdbw7AGHXDftr2akkqHs+0VxKALtQN+35JO4rnOyQ90U45ALpSOT+77cck3SjpStsnJH1V0oOSfmj7Tkm/lfSZLovMrrLP92Q/dUyaqrH2a2bH30PygX2H2i5n4lWGPSK2j2ni7hhgCeF2WSAJwg4kQdiBJAg7kARhB5KovBqPyVfWBbWUv+p5y667StvX7xtmWuSliiM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRBPzsGUzVElX70dnFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk6GdfAqqmbH7q2qU7Zh394cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nQzz4BqvrRH712tqdK+lX1nfZbZsu/Nz7jtMtNVB7Zbe+xfcb2kQXLHrD9e9uHi59buy0TQFOLOY3/jqRbRix/KCKmip8n2y0LQNsqwx4Rs5LO9lALgA41uUB3j+3ni9P8leNWsr3T9pztuQs632BzAJqoG/ZvSVonaUrSKUlfH7diRMxExHRETC/T8pqbA9BUrbBHxOmIeDMi3pL0bUkb2i0LQNtqhd326gUvb5d0ZNy6ACZDZT+77cck3SjpStsnJH1V0o22pySFpOOSyjtEkzv20KbS9iHHo9+8Zqq0var2Lud/f3r3w6XtN++b6mzbl6LKsEfE9hGLH+mgFgAd4nZZIAnCDiRB2IEkCDuQBGEHkmCIaw82b3ppsG1v2VUxTFTlw0TXzEZp+x2btpa2dzk8t6pbcP29TPm8EEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCfvYedP1V0Osev3ts2/p9zfqaq76u+TfaWP4Gu7v726uG195871Rn216KOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL0s18Chhy3XTlt8u5+6kA1juxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAT97D2449Vuv1v9z7ePH1Ne2Q++hFXtV+lcL3UsFZVHdttrbf/U9lHbL9r+UrF8le0Dtl8uHld2Xy6AuhZzGv+GpK9ExMclbZK0y/YNku6TdDAirpd0sHgNYEJVhj0iTkXEc8Xz1yQdlXSNpG2S9har7ZV0W0c1AmjBe7pAZ/ujkj4h6ZCkqyPilDT/H4Kkq8b8zk7bc7bnLuh8w3IB1LXosNv+oKQfSfpyRCz6ykdEzETEdERML9PyOjUCaMGiwm57meaD/r2I+HGx+LTt1UX7aklnuikRQBsqu95sW9Ijko5GxDcWNO2XtEPSg8XjE51UeAn4z5/fUL5Cw6636/7p6Phtby2f1rhqOumq2oecjvo3X/t4aXvVdNTZLKaffbOkz0t6wfbhYtn9mg/5D23fKem3kj7TSYUAWlEZ9oj4mSSPab6p3XIAdIXbZYEkCDuQBGEHkiDsQBKEHUiCIa49WDMb5St8ttn7lw6RbTpddMfTTTdxKQ/f7QJHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ign72HlT1B2/RXaXtT+9+uM1ylox1j99d2r5ew01VvRRxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJOhnnwBN++HLvje+6XTQXdqyq/zvWr+PfvQ2cWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcUf6d5rbXSnpU0l9JekvSTER80/YDkr4o6Q/FqvdHxJNl73WFV8VGM/Er0JVDcVDn4uzIWZcXc1PNG5K+EhHP2f6QpGdtHyjaHoqIf2urUADdWcz87KcknSqev2b7qKRrui4MQLve02d22x+V9AlJb9/feY/t523vsb1yzO/stD1ne+6CzjerFkBtiw677Q9K+pGkL0fEOUnfkrRO0pTmj/xfH/V7ETETEdMRMb1My5tXDKCWRYXd9jLNB/17EfFjSYqI0xHxZkS8JenbkjZ0VyaApirDbtuSHpF0NCK+sWD56gWr3S7pSPvlAWjLYq7Gb5b0eUkv2D5cLLtf0nbbU5JC0nGpYhwmgEEt5mr8zySN6rcr7VMHMFm4gw5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BE5VdJt7ox+w+SXl2w6EpJf+ytgPdmUmub1LokaqurzdqujYi/HNXQa9jftXF7LiKmByugxKTWNql1SdRWV1+1cRoPJEHYgSSGDvvMwNsvM6m1TWpdErXV1Uttg35mB9CfoY/sAHpC2IEkBgm77Vts/9L2Mdv3DVHDOLaP237B9mHbcwPXssf2GdtHFixbZfuA7ZeLx5Fz7A1U2wO2f1/su8O2bx2otrW2f2r7qO0XbX+pWD7oviupq5f91vtndtuXSfqVpE9KOiHpGUnbI+KlXgsZw/ZxSdMRMfgNGLa3SvqTpEcj4q+LZV+TdDYiHiz+o1wZEf88IbU9IOlPQ0/jXcxWtHrhNOOSbpP0BQ2470rq+kf1sN+GOLJvkHQsIl6JiNcl/UDStgHqmHgRMSvp7EWLt0naWzzfq/l/LL0bU9tEiIhTEfFc8fw1SW9PMz7oviupqxdDhP0aSb9b8PqEJmu+95D0E9vP2t45dDEjXB0Rp6T5fzySrhq4notVTuPdp4umGZ+YfVdn+vOmhgj7qKmkJqn/b3NE/K2kT0vaVZyuYnEWNY13X0ZMMz4R6k5/3tQQYT8hae2C1x+RdHKAOkaKiJPF4xlJ+zR5U1GffnsG3eLxzMD1/L9JmsZ71DTjmoB9N+T050OE/RlJ19u+zvblkj4naf8AdbyL7RXFhRPZXiHpU5q8qaj3S9pRPN8h6YkBa3mHSZnGe9w04xp43w0+/XlE9P4j6VbNX5H/taR/GaKGMXV9TNJ/Fz8vDl2bpMc0f1p3QfNnRHdK+rCkg5JeLh5XTVBt35X0gqTnNR+s1QPV9vea/2j4vKTDxc+tQ++7krp62W/cLgskwR10QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wH3QQq5YjB1TwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "responsible-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1, 28 * 28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-cable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
